{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'top_down_attention_lstm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collate_fn\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COCOEvalCap\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtop_down_attention_lstm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TopDownLSTM\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# from topic_unchanged_decoder import TopicSimDecoder\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtopic_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TopicTransformer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'top_down_attention_lstm'"
     ]
    }
   ],
   "source": [
    "#%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import collections\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from transforms import ToTensor, ApplyGain, Resample\n",
    "\n",
    "from dataset import collate_fn\n",
    "from eval import COCOEvalCap\n",
    "\n",
    "\n",
    "from top_down_attention_lstm import TopDownLSTM\n",
    "\n",
    "# from topic_unchanged_decoder import TopicSimDecoder\n",
    "from topic_transformer import TopicTransformer\n",
    "\n",
    "from transformer import Transformer\n",
    "from util import get_loaders, get_loaders_toy_data, FakeDataset\n",
    "from utils_model import beam_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = './training/captioning/models/'\n",
    "\n",
    "use_topic = True\n",
    "checkpoint_loc, param_file =\"./training/transformertopic/models/tansformertopic/TRAN1-2/checkpoints/epoch=16-step=70464.ckpt\", 'config_transformer_muse.json' # 6.08\n",
    "# checkpoint_loc, param_file =\"./training/transformertopic/models/tansformertopic/TRAN1-9/checkpoints/epoch=14-step=11549.ckpt\", 'config_transformer_consult_topic.json' # 6.08\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(1234)\n",
    "params = json.load(open(param_file, 'r'))\n",
    "\n",
    "transform = transforms.Compose([Resample(500), ToTensor(), ApplyGain()])\n",
    "\n",
    "model = TopicTransformer.load_from_checkpoint(checkpoint_path=checkpoint_loc).cuda()\n",
    "\n",
    "threshold, is_train, vocab = 0, False, model.vocab\n",
    "\n",
    "testset_df = pd.read_csv(params['test_labels_csv'], index_col=0)\n",
    "testset = FakeDataset(100, use_topic, vocab, transform=transform)\n",
    "\n",
    "gts = testset_df.apply(lambda x: {x['TestID']: [x['Label']]}, axis=1).to_list()\n",
    "gts = {list(dict_item.keys())[0]: list(dict_item.values())[0][0] for dict_item in gts}\n",
    "test_loader = DataLoader(testset, batch_size=64,\n",
    "                            num_workers=4, collate_fn=collate_fn)\n",
    "# max_length=50\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For transformer topic\n",
    "sample_method = {'temp':None, 'k':None, 'p':None, 'greedy':True, 'm':None}\n",
    "max_length = 50\n",
    "\n",
    "gts = {}\n",
    "res = {}\n",
    "for batch_idx, batch in enumerate(tqdm.tqdm(test_loader)):\n",
    "    waveforms, _, _, ids, targets, _, topic = batch\n",
    "    words = model.sample(waveforms, sample_method, max_length)\n",
    "\n",
    "    generated = model.vocab.decode(words, skip_first=False)\n",
    "    truth = model.vocab.decode(targets)\n",
    "    for i in range(waveforms.shape[0]):\n",
    "        res[ids[i]] = [generated[i]]\n",
    "        gts[ids[i]] = [truth[i]]\n",
    "#         print(res, gts)\n",
    "    # save generations\n",
    "#     pd.DataFrame(gts).to_csv(checkpoint_loc[:-5] + 'gts_.csv')\n",
    "#     pd.DataFrame(res).to_csv(checkpoint_loc[:-5] + 'res_.csv')\n",
    "\n",
    "COCOEval = COCOEvalCap()\n",
    "COCOEval.evaluate(gts, res)\n",
    "#     print(sample_method, COCOEval.eval)\n",
    "print(sample_method, COCOEval.eval)\n",
    "# print(gts, res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
